{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTQ：面向预训练 Transformer 模型设计的量化技术（ICLR 2023）\n",
    "GPTQ：Accurate Post-Training Quantization for Generative Pre-trained Transformers 是一个高效、精准的\n",
    "量化技术，特别适用于大规模GPT模型，能够在显著降低模型大小和计算需求的同时，保持高准确度和推理速度。\n",
    "***\n",
    "GPTQ算法具有以下技术特点：\\\n",
    "\\\n",
    "1.专为GPT模型设计：GPTQ针对大规模GPT模型（如1750亿参数规模的模型）进行优化，解决了这类模型因\n",
    "规模庞大导致的高计算和存储成本问题。\\\n",
    "2.一次性权重量化方法：GPTQ是一种基于近似二阶信息的权重量化方法，能够在一次处理中完成模型的量化。\\\n",
    "3.高效率：GPTQ能在大约四个GPU小时内完成1750亿参数的GPT模型的量化。\\\n",
    "4.低位宽量化：通过将权重位宽降至每个权重3或4位，GPTQ显著减少了模型的大小。\\\n",
    "5.准确度保持：即便在进行显著的位宽减少后，GPTQ也能保持与未压缩模型相近的准确度，减少性能损失。\\\n",
    "6.支持极端量化：GPTQ还可以实现更极端的量化，如2位或三元量化，同时保持合理的准确度。\\\n",
    "7.推理速度提升：使用GPTQ量化的模型在高端GPU（如NVIDIA A100）上实现了大约3.25倍的推理速度提升，\n",
    "在成本效益更高的GPU（如NVIDIA A6000）上实现了大约4.5倍的速度提升。\\\n",
    "8.适用于单GPU环境：GPTQ使得在单个GPU内执行大规模模型的生成推理成为可能，显著降低了部署这类模\n",
    "型的硬件要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](../static/微信图片_20240304084405.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTQ 量化算法核心流程\n",
    "核心步骤：使用存储在Cholesky（切尔斯基）分解中的逆Hessian（海森）\n",
    "信息量化连续列的块（加粗表示），并在步骤结束时更新剩余的权重\n",
    "（蓝色表示），在每个块内递归（白色中间块）地应用量化过程。\\\n",
    "GPTQ量化过程的关键步骤操作，具体描述如下：\\\n",
    "1.块量化：选择一块连续的列（在图中加粗表示），并将其作为当前步骤\n",
    "的量化目标。\\\n",
    "2.使用Cholesky分解：利用Cholesky分解得到的逆Hessian信息来量化选定的块。Cholesky分解提供了一种数值稳定的方法来处理逆矩阵，这对于维\n",
    "持量化过程的准确性至关重要。\\\n",
    "3.权重更新：在每个量化步骤的最后，更新剩余的权重（在图中以蓝色表\n",
    "示）。这个步骤确保了整个量化过程的连贯性和精确性。\\\n",
    "4.递归量化：在每个选定的块内部，量化过程是递归应用的。这意味着量\n",
    "化过程首先聚焦于一个较小的子块，然后逐步扩展到整个块。\n",
    "通过这种方式，GPTQ方法能够在保持高度精度的同时，高效地处理大量\n",
    "的权重，这对于大型模型的量化至关重要。这种策略特别适用于处理大\n",
    "型、复杂的模型，如GPT系列，其中权重数量巨大，且量化过程需要特别\n",
    "小心以避免精度损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 20 100 5 10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel,AutoModelForCausalLM\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model=AutoModelForCausalLM.from_pretrained('E:\\model\\language\\opt-125m',trust_remote_code=True,device_map='auto').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter model.decoder.embed_tokens.weight data type: torch.float16\n",
      "Parameter model.decoder.embed_positions.weight data type: torch.float16\n",
      "Parameter model.decoder.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.0.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.0.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.1.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.1.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.2.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.2.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.3.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.3.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.4.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.4.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.5.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.5.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.6.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.6.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.7.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.7.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.8.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.8.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.9.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.9.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.10.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.10.final_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.k_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.k_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.v_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.v_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.q_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.q_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.out_proj.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn.out_proj.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.self_attn_layer_norm.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.fc1.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.fc1.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.fc2.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.fc2.bias data type: torch.float16\n",
      "Parameter model.decoder.layers.11.final_layer_norm.weight data type: torch.float16\n",
      "Parameter model.decoder.layers.11.final_layer_norm.bias data type: torch.float16\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for name, param in model.named_parameters():\n",
    "    n=n+1\n",
    "    print(f\"Parameter {name} data type: {param.dtype}\")\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
